{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe583a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "\n",
    "################################## set device ##################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## PPO Policy ##################################\n",
    "\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)  # 倒数第一个维度\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            \n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # For Single Action Environments.\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)  # 这里选动作为何用旧网络？\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "            \n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            \n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "#             print(ratios.shape)\n",
    "\n",
    "            # Finding Surrogate Loss\n",
    "            advantages = rewards - state_values.detach()   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "#             print(loss.shape)\n",
    "            \n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fec12fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "training environment name : Hopper-v2\n",
      "current logging run number for Hopper-v2 :  5\n",
      "logging at : PPO_logs/Hopper-v2//PPO_Hopper-v2_log_5.csv\n",
      "save checkpoint path : PPO_preTrained/Hopper-v2/PPO_Hopper-v2_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  3000000\n",
      "max timesteps per episode :  1000\n",
      "model saving frequency : 100000 timesteps\n",
      "log frequency : 2000 timesteps\n",
      "printing average reward over episodes in last : 10000 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  11\n",
      "action space dimension :  3\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a continuous action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "starting std of action distribution :  0.6\n",
      "decay rate of std of action distribution :  0.05\n",
      "minimum std of action distribution :  0.1\n",
      "decay frequency of std of action distribution : 250000 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 4000 timesteps\n",
      "PPO K epochs :  80\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0003\n",
      "optimizer learning rate critic :  0.001\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2021-09-29 18:34:23\n",
      "============================================================================================\n",
      "Episode : 541 \t\t Timestep : 10000 \t\t Average Reward : 13.74\n",
      "Episode : 758 \t\t Timestep : 20000 \t\t Average Reward : 55.69\n",
      "Episode : 867 \t\t Timestep : 30000 \t\t Average Reward : 156.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8048/474101153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# select action with policy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mppo_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8048/977419568.py\u001b[0m in \u001b[0;36mselect_action\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_logprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 这里选动作为何用旧网络？\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8048/977419568.py\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_continuous_action_space\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m             \u001b[0maction_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m             \u001b[0mcov_mat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultivariateNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_mat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "# import pybullet_envs\n",
    "\n",
    "\n",
    "\n",
    "################################### Training ###################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "env_name = \"Hopper-v2\"\n",
    "\n",
    "has_continuous_action_space = True  # continuous action space; else discrete\n",
    "\n",
    "max_ep_len = 1000                   # max timesteps in one episode\n",
    "max_training_timesteps = int(3e6)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "print_freq = max_ep_len * 10        # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2           # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = int(1e5)          # save model frequency (in num timesteps)\n",
    "\n",
    "action_std = 0.6                    # starting std for action distribution (Multivariate Normal)\n",
    "action_std_decay_rate = 0.05        # linearly decay action_std (action_std = action_std - action_std_decay_rate)\n",
    "min_action_std = 0.1                # minimum action_std (stop decay after action_std <= min_action_std)\n",
    "action_std_decay_freq = int(2.5e5)  # action_std decay frequency (in num timesteps)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
    "K_epochs = 80               # update policy for K epochs in one PPO update\n",
    "\n",
    "eps_clip = 0.2          # clip parameter for PPO\n",
    "gamma = 0.99            # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"training environment name : \" + env_name)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "###################### logging ######################\n",
    "\n",
    "#### log files for multiple runs are NOT overwritten\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "\n",
    "#### create new log file for each run\n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "################### checkpointing ###################\n",
    "\n",
    "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "directory = directory + '/' + env_name + '/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"save checkpoint path : \" + checkpoint_path)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\")\n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma) : \", gamma)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "if random_seed:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    env.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "\n",
    "\n",
    "# printing and logging variables\n",
    "print_running_reward = 0\n",
    "print_running_episodes = 0\n",
    "\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps:\n",
    "\n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "\n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "\n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "\n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward = print_running_reward / print_running_episodes\n",
    "            print_avg_reward = round(print_avg_reward, 2)\n",
    "\n",
    "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
    "\n",
    "            print_running_reward = 0\n",
    "            print_running_episodes = 0\n",
    "\n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path)\n",
    "            ppo_agent.save(checkpoint_path)\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward += current_ep_reward\n",
    "    print_running_episodes += 1\n",
    "\n",
    "    log_running_reward += current_ep_reward\n",
    "    log_running_episodes += 1\n",
    "\n",
    "    i_episode += 1\n",
    "\n",
    "\n",
    "log_f.close()\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print total training time\n",
    "print(\"============================================================================================\")\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"Finished training at (GMT) : \", end_time)\n",
    "print(\"Total training time  : \", end_time - start_time)\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e98314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.2973, -0.1119, -0.5779]]),\n",
       " tensor([[ 0.4059, -0.0289,  0.8036]]),\n",
       " tensor([[-0.1604,  0.2859, -0.5824]]),\n",
       " tensor([[-1.1156, -0.1761, -0.7573]]),\n",
       " tensor([[0.0168, 0.5715, 0.2309]]),\n",
       " tensor([[ 0.5662, -0.5858,  0.6337]]),\n",
       " tensor([[ 0.0939, -0.5134,  0.7610]]),\n",
       " tensor([[ 0.7206,  0.5513, -0.3910]]),\n",
       " tensor([[-0.1235, -0.3537, -0.4663]]),\n",
       " tensor([[ 0.2638,  0.4717, -0.5355]]),\n",
       " tensor([[0.7455, 0.9699, 1.0233]]),\n",
       " tensor([[-0.5275,  0.4330, -0.2078]]),\n",
       " tensor([[0.8783, 0.7153, 0.5150]]),\n",
       " tensor([[ 1.3776, -0.0526,  0.4362]]),\n",
       " tensor([[-1.0932, -0.8379, -0.6188]]),\n",
       " tensor([[-0.6690, -0.0066,  0.7339]]),\n",
       " tensor([[-0.7748, -0.5182, -1.0876]]),\n",
       " tensor([[0.8998, 1.4626, 0.6007]]),\n",
       " tensor([[-0.2368, -0.5146,  1.3557]]),\n",
       " tensor([[ 0.0659, -0.2618, -0.0414]]),\n",
       " tensor([[-0.6331, -0.2890,  0.3416]]),\n",
       " tensor([[ 0.4032, -0.2855,  0.0574]]),\n",
       " tensor([[0.7381, 0.5006, 0.5349]]),\n",
       " tensor([[ 0.2442, -0.2110, -0.9563]]),\n",
       " tensor([[-0.4378, -0.0832, -0.6728]]),\n",
       " tensor([[ 0.0983,  0.5897, -0.0839]]),\n",
       " tensor([[-0.5367,  0.6792,  0.0398]]),\n",
       " tensor([[-0.1224, -0.3649, -0.3104]]),\n",
       " tensor([[-1.1102,  0.9148,  0.1163]]),\n",
       " tensor([[-0.8427, -0.1985, -0.8591]]),\n",
       " tensor([[ 1.0268,  1.5211, -0.5167]]),\n",
       " tensor([[ 0.0263,  0.3886, -0.2873]]),\n",
       " tensor([[-0.4058,  0.1101,  0.6026]]),\n",
       " tensor([[ 0.0780, -0.3777,  0.2048]]),\n",
       " tensor([[-0.3784,  1.0799, -0.4440]]),\n",
       " tensor([[-0.2921,  0.0810,  0.6002]]),\n",
       " tensor([[ 0.3784, -0.0680, -1.4239]]),\n",
       " tensor([[ 1.1111,  0.6669, -0.2037]]),\n",
       " tensor([[ 0.4424,  0.5933, -0.0261]]),\n",
       " tensor([[0.5291, 0.7978, 0.2123]]),\n",
       " tensor([[-0.2732,  0.7827, -0.1004]]),\n",
       " tensor([[-0.0826, -0.5225, -0.0995]]),\n",
       " tensor([[0.5843, 0.9486, 0.7745]]),\n",
       " tensor([[-0.3420, -0.4595,  0.3034]]),\n",
       " tensor([[-0.1520,  0.2768,  0.2313]]),\n",
       " tensor([[ 0.2450, -0.4240, -1.2723]]),\n",
       " tensor([[-0.0878,  0.7075, -0.1993]]),\n",
       " tensor([[-0.0397, -0.2160, -0.1666]]),\n",
       " tensor([[0.7142, 0.5640, 1.2077]]),\n",
       " tensor([[0.2415, 0.3970, 0.8376]]),\n",
       " tensor([[-0.1180,  0.7952,  0.6051]]),\n",
       " tensor([[-0.2899, -0.7000, -0.3786]]),\n",
       " tensor([[-0.1835,  0.0863,  0.6668]]),\n",
       " tensor([[-0.4357, -0.4939,  0.4164]]),\n",
       " tensor([[-0.9627, -0.1906, -0.3401]]),\n",
       " tensor([[ 0.1482, -0.1491, -1.1683]]),\n",
       " tensor([[ 0.5058, -0.5465, -0.3652]]),\n",
       " tensor([[-1.7311,  0.3082, -0.4466]]),\n",
       " tensor([[ 0.1039,  0.2296, -0.8661]]),\n",
       " tensor([[ 0.2497, -0.0125, -0.2199]]),\n",
       " tensor([[0.5051, 1.1726, 0.2022]]),\n",
       " tensor([[-1.0797,  0.2944, -0.4419]]),\n",
       " tensor([[ 0.0074, -0.0575,  0.5724]]),\n",
       " tensor([[ 0.2086, -0.4526,  0.2461]]),\n",
       " tensor([[ 1.0396, -0.2891, -0.0161]]),\n",
       " tensor([[-0.7000, -0.3016,  0.2103]]),\n",
       " tensor([[-0.3067, -0.5802, -0.1606]]),\n",
       " tensor([[ 0.3150,  0.1229, -0.3894]]),\n",
       " tensor([[-0.2464,  0.6160, -0.4648]]),\n",
       " tensor([[0.6516, 0.2361, 0.4934]]),\n",
       " tensor([[-0.8437,  0.4482, -1.1589]]),\n",
       " tensor([[ 0.9370, -1.3102, -0.6864]]),\n",
       " tensor([[ 0.0284,  0.5466, -0.1915]]),\n",
       " tensor([[ 0.5167,  0.7024, -0.0220]]),\n",
       " tensor([[-1.0294,  0.8717,  0.4472]]),\n",
       " tensor([[-0.2449,  0.0096,  0.8977]]),\n",
       " tensor([[-1.0816,  0.1603,  0.0039]]),\n",
       " tensor([[-0.3835,  0.7588, -0.5543]]),\n",
       " tensor([[-0.3839, -0.2421, -0.0279]]),\n",
       " tensor([[ 0.4617,  0.7482, -0.4210]]),\n",
       " tensor([[0.1300, 0.5959, 0.5924]]),\n",
       " tensor([[-0.5701,  0.5261,  0.2827]]),\n",
       " tensor([[ 1.2434, -0.6626, -0.4910]]),\n",
       " tensor([[ 0.3088, -0.5497, -0.8273]]),\n",
       " tensor([[ 0.3812, -1.0796,  0.4453]]),\n",
       " tensor([[-0.6638, -0.0980,  0.2878]]),\n",
       " tensor([[-0.7160,  0.3716, -0.9602]]),\n",
       " tensor([[-4.8246e-01, -6.0084e-04, -8.3128e-01]]),\n",
       " tensor([[ 1.3186,  0.3466, -0.5057]]),\n",
       " tensor([[-0.6805, -0.3855,  0.3284]]),\n",
       " tensor([[1.2372, 0.8116, 0.2885]]),\n",
       " tensor([[ 0.6096, -0.2011, -1.0795]]),\n",
       " tensor([[ 0.8688,  0.4717, -0.1331]]),\n",
       " tensor([[-1.1756,  1.0844, -0.6913]]),\n",
       " tensor([[-0.4701,  0.9012, -0.7526]]),\n",
       " tensor([[ 0.5199, -0.4121, -0.7252]]),\n",
       " tensor([[-0.7317,  0.3265,  1.4115]]),\n",
       " tensor([[-0.0707, -0.0765, -0.1639]]),\n",
       " tensor([[ 0.2376, -0.0099, -0.3432]]),\n",
       " tensor([[ 0.0172,  0.8926, -0.7897]]),\n",
       " tensor([[ 0.0448, -0.3733,  0.8167]]),\n",
       " tensor([[-0.4574,  0.2723,  0.9021]]),\n",
       " tensor([[0.7494, 0.3463, 0.4522]]),\n",
       " tensor([[-0.3097, -1.0001,  0.6627]]),\n",
       " tensor([[-0.1478, -0.4578,  0.4141]]),\n",
       " tensor([[-0.2561, -0.2071,  0.4370]]),\n",
       " tensor([[-0.8548,  0.3979, -0.5020]]),\n",
       " tensor([[ 0.1249,  1.0876, -0.3986]]),\n",
       " tensor([[-0.4539, -0.2894, -0.1201]]),\n",
       " tensor([[-0.2617,  1.1573, -0.0756]]),\n",
       " tensor([[ 0.0737,  0.1690, -0.3410]]),\n",
       " tensor([[0.0198, 0.5565, 0.0764]]),\n",
       " tensor([[-0.5606,  0.4560, -0.2459]]),\n",
       " tensor([[ 1.1783,  0.1806, -0.2566]]),\n",
       " tensor([[ 0.6093, -0.9880,  0.8830]]),\n",
       " tensor([[0.2005, 0.7160, 0.5042]]),\n",
       " tensor([[-0.6568,  0.0595, -1.2097]]),\n",
       " tensor([[ 0.2042,  1.8342, -0.6501]]),\n",
       " tensor([[-0.4008, -0.1378, -0.4493]]),\n",
       " tensor([[-0.1775,  1.9531,  0.9480]]),\n",
       " tensor([[ 1.0627,  0.3728, -0.5877]]),\n",
       " tensor([[ 1.5425,  1.0940, -0.4354]]),\n",
       " tensor([[-1.3813, -0.8035, -0.4950]]),\n",
       " tensor([[ 0.7281,  0.4441, -0.4672]]),\n",
       " tensor([[ 0.6399, -0.2421, -0.3723]]),\n",
       " tensor([[0.2023, 1.3043, 0.6079]]),\n",
       " tensor([[1.4972, 1.3255, 0.9678]]),\n",
       " tensor([[0.7855, 0.6246, 0.0550]]),\n",
       " tensor([[-0.1912,  1.7601,  0.6941]]),\n",
       " tensor([[0.4941, 0.7234, 0.5973]]),\n",
       " tensor([[0.1603, 0.7338, 0.5009]]),\n",
       " tensor([[-0.2463, -0.1684,  0.0993]]),\n",
       " tensor([[ 0.0765, -0.0949, -0.8507]]),\n",
       " tensor([[ 0.8827,  1.0883, -0.6437]]),\n",
       " tensor([[ 0.0499, -0.3068, -0.0872]]),\n",
       " tensor([[ 0.3822,  0.3299, -0.6502]]),\n",
       " tensor([[0.6310, 0.1436, 0.5993]]),\n",
       " tensor([[1.2259, 1.3472, 0.1747]]),\n",
       " tensor([[0.7119, 0.4448, 0.3619]]),\n",
       " tensor([[-0.4856, -0.8459,  0.7936]]),\n",
       " tensor([[ 0.7914,  0.5441, -0.1227]]),\n",
       " tensor([[ 0.5918, -0.0221, -0.0616]]),\n",
       " tensor([[-1.4419,  0.2524,  0.9823]]),\n",
       " tensor([[0.2301, 0.2247, 1.0006]]),\n",
       " tensor([[ 0.3910,  0.2215, -1.1737]]),\n",
       " tensor([[ 0.9762,  0.1958, -0.4316]]),\n",
       " tensor([[-1.1170,  0.1235,  0.4704]]),\n",
       " tensor([[-0.5199,  0.0557, -0.5191]]),\n",
       " tensor([[ 0.7671,  0.3799, -0.4324]]),\n",
       " tensor([[0.9431, 0.4448, 0.5156]]),\n",
       " tensor([[-0.0352, -0.0178,  0.0080]]),\n",
       " tensor([[0.6367, 0.3852, 1.2703]]),\n",
       " tensor([[-0.1064,  0.2324, -0.5160]]),\n",
       " tensor([[-0.4533,  0.9236, -0.2187]]),\n",
       " tensor([[-0.2162,  0.7008, -0.1677]]),\n",
       " tensor([[-0.4584, -0.3783, -0.1779]]),\n",
       " tensor([[ 0.6352, -0.0824, -0.2800]]),\n",
       " tensor([[0.2026, 1.0968, 0.0252]]),\n",
       " tensor([[ 0.3587,  0.7663, -0.2007]]),\n",
       " tensor([[-0.3709,  0.1398,  0.5404]]),\n",
       " tensor([[ 0.6981,  0.4570, -0.7965]]),\n",
       " tensor([[ 1.1584,  0.2846, -0.3259]]),\n",
       " tensor([[ 0.3016, -0.0311,  1.2728]]),\n",
       " tensor([[ 1.8388, -0.2821,  0.4710]]),\n",
       " tensor([[0.6261, 1.0089, 0.6541]]),\n",
       " tensor([[-1.1314,  0.5023,  0.3732]]),\n",
       " tensor([[-0.3173, -0.3904, -0.3278]]),\n",
       " tensor([[ 0.1164,  0.5031, -0.3598]]),\n",
       " tensor([[ 0.5667, -0.0617,  0.6846]]),\n",
       " tensor([[-0.3766,  0.0870,  0.5909]]),\n",
       " tensor([[-0.0568,  0.2669,  0.1706]]),\n",
       " tensor([[1.4291, 0.8514, 0.1784]]),\n",
       " tensor([[ 0.7238, -0.2739,  0.1546]]),\n",
       " tensor([[ 1.3961,  0.3608, -0.3958]]),\n",
       " tensor([[ 0.7765, -1.2953,  0.0693]]),\n",
       " tensor([[-0.0116,  1.1198,  0.4109]]),\n",
       " tensor([[-0.6296,  0.7230,  0.4619]]),\n",
       " tensor([[-0.8182, -1.0956,  0.6491]]),\n",
       " tensor([[-0.9325,  0.1298,  0.3412]]),\n",
       " tensor([[ 1.0940, -0.0089, -0.6592]]),\n",
       " tensor([[ 0.2126, -0.5203,  0.2337]]),\n",
       " tensor([[-0.7629,  0.1250, -0.7908]]),\n",
       " tensor([[-0.7896, -0.1735,  0.1011]]),\n",
       " tensor([[ 0.1441,  0.4260, -0.2755]]),\n",
       " tensor([[ 0.5158,  0.2995, -1.4310]]),\n",
       " tensor([[ 0.6162,  0.1763, -0.1939]]),\n",
       " tensor([[0.4174, 1.1909, 0.6587]]),\n",
       " tensor([[ 0.6673,  1.1092, -0.3974]]),\n",
       " tensor([[-0.4256, -0.1087, -0.2528]]),\n",
       " tensor([[ 0.1322,  0.9354, -0.1268]]),\n",
       " tensor([[-0.7605,  0.3033,  0.7814]]),\n",
       " tensor([[-0.1978, -0.6906, -0.0591]]),\n",
       " tensor([[0.8370, 0.0689, 1.0420]]),\n",
       " tensor([[ 0.1696, -1.4405, -0.0983]]),\n",
       " tensor([[-0.0102, -0.0146, -1.2675]]),\n",
       " tensor([[-0.6831,  0.7799, -0.3011]]),\n",
       " tensor([[-0.7191, -0.6017, -0.0747]]),\n",
       " tensor([[ 1.0631, -0.1914,  0.5067]]),\n",
       " tensor([[ 1.1086, -0.2400, -0.0239]]),\n",
       " tensor([[-0.6398,  0.4467, -0.1811]]),\n",
       " tensor([[-0.2467, -0.5506,  0.4705]]),\n",
       " tensor([[ 0.6208, -0.1913, -0.0243]]),\n",
       " tensor([[-0.7946, -0.4408, -0.3272]]),\n",
       " tensor([[ 0.0348, -0.0093,  0.5740]]),\n",
       " tensor([[-0.2772,  0.6835, -1.3716]]),\n",
       " tensor([[-0.5270,  0.0571,  0.6438]]),\n",
       " tensor([[-0.2907, -0.4477, -0.4555]]),\n",
       " tensor([[ 1.1396,  0.9970, -0.2222]]),\n",
       " tensor([[ 0.0810, -0.4050, -0.3099]]),\n",
       " tensor([[-1.0911,  0.0506, -1.6293]]),\n",
       " tensor([[0.4120, 0.3771, 1.0734]]),\n",
       " tensor([[0.6225, 0.7460, 0.4629]]),\n",
       " tensor([[-0.1353,  0.5478,  0.2397]]),\n",
       " tensor([[ 0.1378, -0.9281,  0.3790]]),\n",
       " tensor([[-0.3735,  0.2592, -0.4670]]),\n",
       " tensor([[-0.5647, -0.0334, -1.3525]]),\n",
       " tensor([[0.3406, 0.4740, 0.7047]]),\n",
       " tensor([[ 0.3151, -0.3437,  0.1329]]),\n",
       " tensor([[-0.1827, -0.0176, -0.5363]]),\n",
       " tensor([[ 0.4208, -0.5451,  0.2230]]),\n",
       " tensor([[-0.8780,  0.9107, -0.1992]]),\n",
       " tensor([[ 0.0731,  0.2477, -0.1702]]),\n",
       " tensor([[-0.3426,  0.3254,  1.1804]]),\n",
       " tensor([[ 0.6041,  0.3326, -0.6312]]),\n",
       " tensor([[1.3617, 0.8611, 1.5558]]),\n",
       " tensor([[-1.2637, -0.1138, -0.2439]]),\n",
       " tensor([[-0.4105,  0.0582,  0.4993]]),\n",
       " tensor([[0.2577, 0.0953, 0.5301]]),\n",
       " tensor([[-0.0701, -0.7350, -0.5369]]),\n",
       " tensor([[ 0.1631, -0.0133, -0.5360]]),\n",
       " tensor([[-0.7997,  0.6183,  1.2384]]),\n",
       " tensor([[-0.1955,  0.2154, -0.6074]]),\n",
       " tensor([[ 0.2068, -0.2439, -1.1387]]),\n",
       " tensor([[-1.4107,  0.6793, -0.3755]]),\n",
       " tensor([[-0.8517,  0.0255,  1.4000]]),\n",
       " tensor([[-0.6331,  0.3734,  0.2265]]),\n",
       " tensor([[0.2079, 0.0037, 0.3337]]),\n",
       " tensor([[ 0.4437, -0.1584,  0.2458]]),\n",
       " tensor([[-0.0536,  0.8376,  0.1257]]),\n",
       " tensor([[-0.8150, -0.0287, -1.1826]]),\n",
       " tensor([[-0.7520,  0.4361,  0.6778]]),\n",
       " tensor([[ 0.1076, -0.7482,  0.2764]]),\n",
       " tensor([[-0.5357, -0.2388,  0.2056]]),\n",
       " tensor([[-0.2148,  0.2281,  0.2816]]),\n",
       " tensor([[-1.1733, -0.1682,  0.0057]]),\n",
       " tensor([[ 0.3924,  0.0958, -0.1092]]),\n",
       " tensor([[ 0.5666,  0.7231, -0.6163]]),\n",
       " tensor([[ 0.2396,  0.6920, -0.5488]]),\n",
       " tensor([[ 0.9105,  0.1076, -0.9427]]),\n",
       " tensor([[0.0051, 0.2967, 0.8397]]),\n",
       " tensor([[ 0.3415, -0.4659,  0.5309]]),\n",
       " tensor([[ 0.3024,  0.1983, -0.8898]]),\n",
       " tensor([[0.1428, 0.6979, 0.9097]]),\n",
       " tensor([[ 1.0300, -0.0044,  0.8076]]),\n",
       " tensor([[-1.4806,  1.2580, -0.6756]]),\n",
       " tensor([[1.3210, 0.0138, 1.0427]]),\n",
       " tensor([[ 0.8935,  0.0057, -0.0461]]),\n",
       " tensor([[0.2264, 0.4540, 0.2156]]),\n",
       " tensor([[ 0.8604, -0.5874,  0.6693]]),\n",
       " tensor([[ 0.2122,  0.1847, -0.0430]]),\n",
       " tensor([[0.9888, 0.1106, 0.4773]]),\n",
       " tensor([[-0.3486,  0.5138, -0.0505]]),\n",
       " tensor([[0.5992, 0.3515, 0.1911]]),\n",
       " tensor([[ 0.7782, -0.0426, -0.1414]]),\n",
       " tensor([[ 1.1697,  1.2213, -1.4178]]),\n",
       " tensor([[ 0.9335,  0.6076, -0.0509]]),\n",
       " tensor([[-0.0660, -0.5366,  0.3468]]),\n",
       " tensor([[0.6438, 0.5082, 0.2445]]),\n",
       " tensor([[ 0.1207, -0.5816,  0.3604]]),\n",
       " tensor([[-0.1822,  0.4741, -0.1827]]),\n",
       " tensor([[0.7520, 0.3207, 0.0271]]),\n",
       " tensor([[ 0.9913, -0.4555,  0.0883]]),\n",
       " tensor([[-0.2497, -0.6187, -0.1900]]),\n",
       " tensor([[0.6655, 0.6413, 0.8026]]),\n",
       " tensor([[-0.9374, -0.6198,  0.2211]]),\n",
       " tensor([[ 0.4668,  0.5493, -0.0610]]),\n",
       " tensor([[0.5599, 0.2046, 0.2323]]),\n",
       " tensor([[0.2415, 0.6908, 0.0835]]),\n",
       " tensor([[ 0.2448,  0.1309, -0.5926]]),\n",
       " tensor([[ 0.2828,  0.0892, -0.5404]]),\n",
       " tensor([[-0.3215,  0.9246,  0.6667]]),\n",
       " tensor([[-0.4017, -0.6476, -0.1854]]),\n",
       " tensor([[0.5387, 1.1183, 0.8176]]),\n",
       " tensor([[ 0.3765, -0.1253, -1.0567]]),\n",
       " tensor([[-0.3030,  0.0972,  0.1636]]),\n",
       " tensor([[-0.8793, -0.6948, -0.2423]]),\n",
       " tensor([[-0.0901,  1.6363,  1.1984]]),\n",
       " tensor([[-0.0951, -1.0898,  0.4591]]),\n",
       " tensor([[ 0.0315, -0.7851, -0.4730]]),\n",
       " tensor([[-0.0349, -0.1581, -0.3981]]),\n",
       " tensor([[0.1020, 0.1717, 0.0798]]),\n",
       " tensor([[-0.8112,  0.2868,  0.3457]]),\n",
       " tensor([[-0.2632,  0.2498, -0.0823]]),\n",
       " tensor([[0.5013, 0.2212, 0.0926]]),\n",
       " tensor([[ 0.2592, -0.3910, -0.7227]]),\n",
       " tensor([[ 1.2089,  0.2561, -0.4935]]),\n",
       " tensor([[-1.0769,  1.7589,  0.2441]]),\n",
       " tensor([[ 0.7002, -0.5373,  0.2950]]),\n",
       " tensor([[-0.0855, -0.7293,  0.0807]]),\n",
       " tensor([[0.9163, 0.2315, 0.3355]]),\n",
       " tensor([[-0.7749, -0.0767, -0.6890]]),\n",
       " tensor([[-0.6389, -0.5313,  0.5866]]),\n",
       " tensor([[ 0.4152,  0.5186, -0.1928]]),\n",
       " tensor([[ 0.8605, -0.5642,  0.3150]]),\n",
       " tensor([[ 0.1103,  0.0257, -0.8861]]),\n",
       " tensor([[-0.7552, -0.0153, -0.9894]]),\n",
       " tensor([[0.8167, 0.0957, 0.5042]]),\n",
       " tensor([[-0.0643,  1.2857,  0.9799]]),\n",
       " tensor([[-0.1966,  0.6888,  0.1435]]),\n",
       " tensor([[0.1019, 0.7076, 0.3979]]),\n",
       " tensor([[0.2011, 0.3048, 0.0763]]),\n",
       " tensor([[-0.5419, -0.3178,  0.9008]]),\n",
       " tensor([[ 1.0236,  0.0415, -1.2680]]),\n",
       " tensor([[-0.1088, -0.4638,  0.3212]]),\n",
       " tensor([[-0.9547,  0.8512,  0.9860]]),\n",
       " tensor([[ 0.3067,  0.1098, -0.0937]]),\n",
       " tensor([[ 0.4262, -0.7492, -0.0963]]),\n",
       " tensor([[ 0.5582,  0.0625, -0.6110]]),\n",
       " tensor([[-0.7247,  0.1864, -0.0993]]),\n",
       " tensor([[-0.3797,  0.3334,  0.1817]]),\n",
       " tensor([[ 0.2792, -1.0040,  0.5729]]),\n",
       " tensor([[-0.7151, -0.6534, -0.2325]]),\n",
       " tensor([[ 0.2621,  0.4908, -1.2050]]),\n",
       " tensor([[ 0.5480, -0.5219, -0.3102]]),\n",
       " tensor([[-1.1128, -0.1126, -0.3502]]),\n",
       " tensor([[-0.5454,  0.2642,  0.6998]]),\n",
       " tensor([[ 0.4839, -0.2437,  0.0468]]),\n",
       " tensor([[-0.7944,  0.3470, -0.0970]]),\n",
       " tensor([[0.4459, 0.1190, 0.8789]]),\n",
       " tensor([[ 0.6763, -0.5677, -0.3734]]),\n",
       " tensor([[ 0.3264, -0.1515,  1.3930]]),\n",
       " tensor([[-0.2793,  0.6117, -0.1840]]),\n",
       " tensor([[-0.1478,  0.3803, -0.3720]]),\n",
       " tensor([[ 0.0367, -0.1152,  0.6525]]),\n",
       " tensor([[ 0.0755,  0.5504, -0.6851]]),\n",
       " tensor([[-0.0369,  0.5721, -0.1508]]),\n",
       " tensor([[-0.0679,  0.4515,  1.0112]]),\n",
       " tensor([[-0.3447, -0.2232, -0.2405]]),\n",
       " tensor([[-1.0177e+00,  8.5439e-04,  8.5233e-01]]),\n",
       " tensor([[-0.5491, -0.7100, -0.1808]]),\n",
       " tensor([[1.1609, 0.3957, 0.0165]]),\n",
       " tensor([[-0.0772,  0.2531, -1.6260]]),\n",
       " tensor([[ 0.9099,  1.0737, -0.2334]]),\n",
       " tensor([[-0.2812,  1.2080,  0.9430]]),\n",
       " tensor([[-1.0110,  0.5090,  1.3117]]),\n",
       " tensor([[0.1653, 0.1593, 0.3340]]),\n",
       " tensor([[0.7834, 0.2101, 0.2261]]),\n",
       " tensor([[-1.3742,  0.5364,  0.3091]]),\n",
       " tensor([[0.8924, 0.4053, 0.2103]]),\n",
       " tensor([[-0.7910, -0.3937, -0.3100]]),\n",
       " tensor([[0.3740, 0.7092, 0.2766]]),\n",
       " tensor([[-0.2338,  0.6055, -1.7289]]),\n",
       " tensor([[-0.6882, -1.3280,  0.2557]]),\n",
       " tensor([[ 0.1501, -0.0731, -0.0459]]),\n",
       " tensor([[-0.2898,  0.5588, -0.0110]]),\n",
       " tensor([[0.1498, 0.1991, 0.7772]]),\n",
       " tensor([[ 0.5737,  0.7354, -0.3603]]),\n",
       " tensor([[ 0.1194, -0.3881,  0.0990]]),\n",
       " tensor([[ 0.6637, -0.2845,  0.5466]]),\n",
       " tensor([[-0.5512,  0.9509,  0.3550]]),\n",
       " tensor([[-0.3265,  0.7348,  0.2368]]),\n",
       " tensor([[0.1161, 0.5557, 0.5403]]),\n",
       " tensor([[-0.6715,  0.5516,  1.2415]]),\n",
       " tensor([[-0.1753,  0.8805, -0.5336]]),\n",
       " tensor([[-0.1170,  1.3028,  0.3109]]),\n",
       " tensor([[-0.2177,  0.4737,  0.1151]]),\n",
       " tensor([[ 1.2817, -1.2592, -0.0078]]),\n",
       " tensor([[ 0.4692,  0.3971, -0.0847]]),\n",
       " tensor([[ 1.2098,  1.3003, -0.3611]]),\n",
       " tensor([[-0.5775,  0.2635, -1.1383]]),\n",
       " tensor([[1.4036, 0.2362, 0.4313]]),\n",
       " tensor([[0.7598, 0.4376, 0.5413]]),\n",
       " tensor([[0.6827, 0.8093, 1.5960]]),\n",
       " tensor([[0.5422, 0.0278, 0.5386]]),\n",
       " tensor([[ 0.7042, -1.0570,  0.1593]]),\n",
       " tensor([[0.2055, 0.5549, 0.1981]]),\n",
       " tensor([[ 0.3584,  1.0805, -0.1410]]),\n",
       " tensor([[ 0.0040, -0.4910,  0.7901]]),\n",
       " tensor([[ 0.7956,  0.3037, -1.4498]]),\n",
       " tensor([[0.4702, 1.0921, 1.0265]]),\n",
       " tensor([[-0.2536, -0.1080,  0.6636]]),\n",
       " tensor([[ 0.9589, -0.2835,  0.2544]]),\n",
       " tensor([[-0.2170, -0.2430, -0.3656]]),\n",
       " tensor([[0.0160, 0.5192, 1.2467]]),\n",
       " tensor([[ 0.7002, -0.0924, -0.7438]]),\n",
       " tensor([[-0.7835,  1.3261, -0.1870]]),\n",
       " tensor([[ 1.5022, -0.0508, -0.5894]]),\n",
       " tensor([[-0.4307, -0.6513, -0.0374]]),\n",
       " tensor([[0.2410, 0.0011, 0.5564]]),\n",
       " tensor([[ 0.2770, -0.4403, -0.7662]]),\n",
       " tensor([[-0.1394,  0.3599,  0.3857]]),\n",
       " tensor([[-0.1149,  0.2586,  1.2196]]),\n",
       " tensor([[-0.6072, -0.3399, -0.4817]]),\n",
       " tensor([[-0.8847,  0.7948, -0.5704]]),\n",
       " tensor([[ 0.4951,  0.3874, -0.8597]]),\n",
       " tensor([[0.5862, 0.3530, 0.5580]]),\n",
       " tensor([[ 0.0194,  0.3434, -0.1385]]),\n",
       " tensor([[ 0.1459, -0.7210, -0.2562]]),\n",
       " tensor([[-0.1865, -0.0524, -0.0450]]),\n",
       " tensor([[-1.2909, -0.2381,  0.6660]]),\n",
       " tensor([[-0.3497,  0.0939,  0.6478]]),\n",
       " tensor([[-0.6534,  1.1806,  0.1815]]),\n",
       " tensor([[ 1.0135,  0.6663, -0.0534]]),\n",
       " tensor([[-0.0200,  0.0832, -0.0287]]),\n",
       " tensor([[ 0.0048, -0.0624, -0.3284]]),\n",
       " tensor([[0.6931, 0.3419, 0.1708]]),\n",
       " tensor([[-0.9882,  0.0328,  0.3456]]),\n",
       " tensor([[ 1.5756, -0.4305, -0.1728]]),\n",
       " tensor([[0.0313, 0.0247, 1.1946]]),\n",
       " tensor([[-0.7690,  0.4725, -0.2320]]),\n",
       " tensor([[ 0.6935, -0.0515, -0.0555]]),\n",
       " tensor([[ 0.5849,  1.0299, -0.1664]]),\n",
       " tensor([[ 0.0171, -0.4524, -0.2391]]),\n",
       " tensor([[ 0.1751, -0.3383,  0.1089]]),\n",
       " tensor([[ 0.5178, -0.6262, -0.3832]]),\n",
       " tensor([[ 0.5873,  0.4276, -0.3714]]),\n",
       " tensor([[ 0.1852, -0.9616,  0.4681]]),\n",
       " tensor([[-0.3883, -0.4186, -0.3943]]),\n",
       " tensor([[1.1600, 0.4339, 0.0697]]),\n",
       " tensor([[ 0.5913,  0.5013, -0.3685]]),\n",
       " tensor([[ 0.5945, -0.7655, -0.9226]]),\n",
       " tensor([[ 0.3776,  0.4293, -0.6473]]),\n",
       " tensor([[0.5912, 0.6965, 1.0743]]),\n",
       " tensor([[-0.5618,  0.1776,  0.0149]]),\n",
       " tensor([[ 0.6745, -0.6548,  1.0816]]),\n",
       " tensor([[0.1722, 0.6942, 0.4629]]),\n",
       " tensor([[-0.3281,  0.6789,  0.7229]]),\n",
       " tensor([[ 0.4873, -0.1180, -0.5909]]),\n",
       " tensor([[-0.4191,  0.9991,  0.8676]]),\n",
       " tensor([[0.1586, 0.6788, 1.0926]]),\n",
       " tensor([[-0.3028,  0.0621, -0.2487]]),\n",
       " tensor([[ 0.4589, -1.2059, -1.0915]]),\n",
       " tensor([[ 0.5876, -0.1415,  0.2209]]),\n",
       " tensor([[-0.5557,  0.1635,  0.0439]]),\n",
       " tensor([[-0.4570,  0.5011, -0.4251]]),\n",
       " tensor([[-0.2861,  0.4894,  0.2459]]),\n",
       " tensor([[0.2687, 0.6737, 0.5084]]),\n",
       " tensor([[0.1182, 0.6253, 0.6265]]),\n",
       " tensor([[-0.4025, -0.4716,  0.8844]]),\n",
       " tensor([[ 0.4736, -0.7540, -1.1068]]),\n",
       " tensor([[ 0.6734, -1.0973, -0.5092]]),\n",
       " tensor([[-0.2563,  0.3121,  0.4382]]),\n",
       " tensor([[ 0.6133,  0.4030, -0.9112]]),\n",
       " tensor([[-0.5012,  0.6624, -0.6758]]),\n",
       " tensor([[ 0.6358, -0.6045, -0.5454]]),\n",
       " tensor([[-0.4166,  0.7743,  0.7033]]),\n",
       " tensor([[-0.7699,  0.5238,  1.0601]]),\n",
       " tensor([[0.3902, 0.9909, 1.0189]]),\n",
       " tensor([[-0.6314,  0.5395,  0.1776]]),\n",
       " tensor([[ 0.4473, -0.7252,  0.5623]]),\n",
       " tensor([[ 0.9795, -0.1813, -0.1197]]),\n",
       " tensor([[ 0.2692, -0.7772, -1.1459]]),\n",
       " tensor([[0.3016, 0.0084, 0.2033]]),\n",
       " tensor([[ 0.7712, -0.0960, -0.1804]]),\n",
       " tensor([[ 0.3255, -1.0587,  0.8992]]),\n",
       " tensor([[-0.1592,  0.7169, -0.1743]]),\n",
       " tensor([[-0.3224, -0.1905, -0.7796]]),\n",
       " tensor([[-0.4768,  0.8279, -0.8322]]),\n",
       " tensor([[-1.0785, -1.0209,  0.3883]]),\n",
       " tensor([[-0.2638, -0.0051, -0.0183]]),\n",
       " tensor([[ 0.1913,  0.5284, -0.2095]]),\n",
       " tensor([[ 0.1251,  0.4396, -0.5760]]),\n",
       " tensor([[-0.1448,  0.0503,  1.7374]]),\n",
       " tensor([[ 1.1519, -0.7752, -0.5981]]),\n",
       " tensor([[ 0.1176,  0.4204, -0.2196]]),\n",
       " tensor([[0.0515, 0.3592, 0.6805]]),\n",
       " tensor([[ 0.1295,  0.2552, -0.0639]]),\n",
       " tensor([[-0.0372,  0.3003, -0.4277]]),\n",
       " tensor([[ 0.0892,  0.0152, -0.0945]]),\n",
       " tensor([[ 0.2928, -0.0248,  0.3790]]),\n",
       " tensor([[-1.0018, -0.3662,  1.1716]]),\n",
       " tensor([[-0.3613, -0.3624,  0.5801]]),\n",
       " tensor([[-0.6117, -0.2846,  0.4948]]),\n",
       " tensor([[-0.0180,  0.0524, -0.3033]]),\n",
       " tensor([[ 1.0753, -0.0895, -0.4921]]),\n",
       " tensor([[ 0.2649,  0.5434, -0.2929]]),\n",
       " tensor([[0.2256, 0.3201, 0.1924]]),\n",
       " tensor([[ 0.0938, -0.9044, -1.0720]]),\n",
       " tensor([[-0.5150,  0.3216,  0.3951]]),\n",
       " tensor([[-0.1501,  1.3329,  1.0793]]),\n",
       " tensor([[0.8648, 0.2623, 0.0570]]),\n",
       " tensor([[-0.5178,  0.1125,  0.3610]]),\n",
       " tensor([[0.1755, 1.1151, 0.2237]]),\n",
       " tensor([[-0.1312, -0.8656,  0.5378]]),\n",
       " tensor([[0.3329, 0.3415, 0.0402]]),\n",
       " tensor([[-0.4026, -0.2444, -0.1829]]),\n",
       " tensor([[-1.1181,  0.0509, -0.2478]]),\n",
       " tensor([[-1.0953,  0.3667, -1.2982]]),\n",
       " tensor([[-1.1167, -0.3618,  0.4597]]),\n",
       " tensor([[0.2406, 0.3309, 0.5995]]),\n",
       " tensor([[-0.0341, -1.0217, -0.6716]]),\n",
       " tensor([[ 0.9027, -0.6927, -1.5885]]),\n",
       " tensor([[ 0.5568, -0.0459,  0.0668]]),\n",
       " tensor([[-0.3714, -0.2321, -1.8002]]),\n",
       " tensor([[ 0.2565,  0.4039, -0.2920]]),\n",
       " tensor([[-0.5807,  1.0777,  0.3573]]),\n",
       " tensor([[ 1.1130,  0.1039, -0.5835]]),\n",
       " tensor([[ 0.0761,  0.4997, -0.7842]]),\n",
       " tensor([[ 0.8893, -0.2193,  0.2581]]),\n",
       " tensor([[-0.2544,  1.2003,  0.1496]]),\n",
       " tensor([[-0.7472,  0.3047,  0.2502]]),\n",
       " tensor([[-0.1005, -0.4057,  0.9165]]),\n",
       " tensor([[-0.5141, -0.0133, -0.4082]]),\n",
       " tensor([[ 0.4482, -0.6815,  0.8757]]),\n",
       " tensor([[ 1.0577,  1.2560, -0.3606]]),\n",
       " tensor([[-0.6632,  0.1748,  0.0407]]),\n",
       " tensor([[-0.4137, -0.1709, -0.4639]]),\n",
       " tensor([[ 2.0763, -0.6393, -0.6191]]),\n",
       " tensor([[-0.7886, -1.1436,  0.2843]]),\n",
       " tensor([[ 0.8211, -0.1920, -0.5627]]),\n",
       " tensor([[-0.0362, -0.3821, -0.4629]]),\n",
       " tensor([[-0.7681,  0.5720, -0.3268]]),\n",
       " tensor([[0.5080, 0.9204, 0.6916]]),\n",
       " tensor([[-1.3772,  0.2721,  0.3020]]),\n",
       " tensor([[ 0.2489, -1.1163,  0.0135]]),\n",
       " tensor([[ 0.1761, -0.7590,  0.3646]]),\n",
       " tensor([[ 0.3086,  1.0078, -0.2821]]),\n",
       " tensor([[-0.0784,  0.8550, -0.1164]]),\n",
       " tensor([[ 0.5144,  0.2328, -0.0242]]),\n",
       " tensor([[-0.4133,  0.0213,  0.7860]]),\n",
       " tensor([[-0.4820,  0.1176,  0.8104]]),\n",
       " tensor([[-0.3898, -1.3056, -0.2930]]),\n",
       " tensor([[-0.2321,  0.9601, -1.1036]]),\n",
       " tensor([[-0.0710, -0.0777,  0.3603]]),\n",
       " tensor([[-0.8214,  0.1879,  0.4486]]),\n",
       " tensor([[0.3437, 0.4519, 0.3785]]),\n",
       " tensor([[0.8999, 0.7369, 0.5062]]),\n",
       " tensor([[0.4909, 0.2764, 1.2161]]),\n",
       " tensor([[-0.9035,  0.6578,  1.1898]]),\n",
       " tensor([[0.7520, 0.9288, 1.0079]]),\n",
       " tensor([[ 0.0456,  0.9513, -0.1310]]),\n",
       " tensor([[0.4090, 0.7689, 0.2433]]),\n",
       " tensor([[-0.3514,  0.9749, -0.3388]]),\n",
       " tensor([[ 0.9554,  0.4248, -0.1998]]),\n",
       " tensor([[-0.0417, -0.1679,  0.7386]]),\n",
       " tensor([[-0.7167,  0.3545, -0.5142]]),\n",
       " tensor([[-0.1001,  0.9293, -0.4452]]),\n",
       " tensor([[-0.6297,  0.3698, -0.1168]]),\n",
       " tensor([[0.2856, 0.7628, 0.6705]]),\n",
       " tensor([[-0.2672,  0.5637, -0.1169]]),\n",
       " tensor([[-0.1159, -0.3301,  0.6323]]),\n",
       " tensor([[0.5312, 0.6516, 0.5561]]),\n",
       " tensor([[-0.9135,  0.7053, -0.5649]]),\n",
       " tensor([[-0.8937,  0.5639, -0.3597]]),\n",
       " tensor([[-0.7963, -0.2141,  0.4887]]),\n",
       " tensor([[-0.9929,  0.1437, -0.0531]]),\n",
       " tensor([[ 0.8590,  0.5037, -0.3517]]),\n",
       " tensor([[ 0.1753,  0.2189, -0.7335]]),\n",
       " tensor([[ 1.4412,  0.5521, -0.3847]]),\n",
       " tensor([[ 0.3860,  0.5116, -0.1352]]),\n",
       " tensor([[-0.0978,  0.4061, -0.4465]]),\n",
       " tensor([[-0.5771, -1.0620,  0.7901]]),\n",
       " tensor([[-0.2665,  0.3022, -0.1079]]),\n",
       " tensor([[ 0.2589,  1.2125, -0.1213]]),\n",
       " tensor([[0.5482, 0.1423, 0.7098]]),\n",
       " tensor([[-0.2181,  0.8448,  0.3595]]),\n",
       " tensor([[1.0216, 0.8378, 0.7962]]),\n",
       " tensor([[ 0.3647, -0.3493,  0.1816]]),\n",
       " tensor([[-0.7897, -0.0126, -0.0455]]),\n",
       " tensor([[-0.8249,  0.4597,  0.4977]]),\n",
       " tensor([[-0.6343,  0.5037, -0.5075]]),\n",
       " tensor([[-0.8247,  0.1508, -0.8496]]),\n",
       " tensor([[-0.3092, -0.2350,  1.0268]]),\n",
       " tensor([[ 0.1863, -0.8919, -0.4344]]),\n",
       " tensor([[ 0.3088,  2.3783, -0.4938]]),\n",
       " tensor([[-0.2520,  0.6441, -0.4645]]),\n",
       " tensor([[ 0.7860, -0.0794,  0.3264]]),\n",
       " tensor([[1.2962, 1.1719, 0.0637]]),\n",
       " tensor([[-0.8662,  0.3431,  1.0163]]),\n",
       " tensor([[ 1.1086, -0.6246,  0.1866]]),\n",
       " tensor([[-0.4041, -0.3095, -0.2045]]),\n",
       " tensor([[ 0.3539,  0.0981, -0.2113]]),\n",
       " tensor([[ 1.2839, -0.0712,  0.5306]]),\n",
       " tensor([[ 0.5442, -0.3337,  0.6627]]),\n",
       " tensor([[ 1.3157, -1.3892, -0.0634]]),\n",
       " tensor([[ 0.5319, -0.6633,  0.6303]]),\n",
       " tensor([[0.4263, 1.3258, 0.8355]]),\n",
       " tensor([[ 0.0354, -0.6503,  0.3497]]),\n",
       " tensor([[ 0.3239, -0.5480,  0.4433]]),\n",
       " tensor([[ 0.0528,  0.4141, -0.6413]]),\n",
       " tensor([[ 0.1244,  0.2030, -1.1350]]),\n",
       " tensor([[-0.3961,  0.2183, -0.2090]]),\n",
       " tensor([[ 0.3900,  1.0526, -0.6977]]),\n",
       " tensor([[-0.5161,  0.8625, -0.1772]]),\n",
       " tensor([[-0.4750,  1.0949,  0.1153]]),\n",
       " tensor([[ 0.7472,  0.0917, -0.0958]]),\n",
       " tensor([[0.5886, 0.4589, 0.4078]]),\n",
       " tensor([[-0.4741,  0.6475, -0.1051]]),\n",
       " tensor([[ 0.8767, -0.7942,  0.3408]]),\n",
       " tensor([[ 0.7146,  0.4992, -0.1162]]),\n",
       " tensor([[-0.3149, -1.0640,  1.2508]]),\n",
       " tensor([[-0.4858,  1.0851,  0.1781]]),\n",
       " tensor([[-1.0253,  0.2314,  1.0470]]),\n",
       " tensor([[-0.5497,  0.1548, -0.9187]]),\n",
       " tensor([[0.1418, 0.5444, 0.0304]]),\n",
       " tensor([[ 0.7130,  0.7843, -0.5744]]),\n",
       " tensor([[ 0.6353, -0.4369,  0.4964]]),\n",
       " tensor([[-0.1084, -0.0294, -0.6073]]),\n",
       " tensor([[-0.6742, -0.6244, -0.5627]]),\n",
       " tensor([[ 0.4692, -0.3351, -0.7898]]),\n",
       " tensor([[ 0.0314, -0.0932, -0.3335]]),\n",
       " tensor([[-0.3889,  0.3680, -0.6560]]),\n",
       " tensor([[-0.3271,  1.3297,  0.3968]]),\n",
       " tensor([[-0.0560, -0.1098,  0.5163]]),\n",
       " tensor([[-0.5985, -1.1046,  1.1097]]),\n",
       " tensor([[-0.8271, -0.4275, -0.4620]]),\n",
       " tensor([[-0.7073,  0.8108, -0.8015]]),\n",
       " tensor([[-0.2138,  0.2639,  0.0607]]),\n",
       " tensor([[ 2.0720, -0.1576,  0.0823]]),\n",
       " tensor([[0.2641, 1.2933, 1.0339]]),\n",
       " tensor([[0.6281, 0.1956, 1.0038]]),\n",
       " tensor([[ 0.2606, -0.9464, -0.8541]]),\n",
       " tensor([[ 0.6292,  0.9422, -0.4209]]),\n",
       " tensor([[-0.1439, -0.2107, -0.3140]]),\n",
       " tensor([[ 0.6812, -0.3246, -0.0013]]),\n",
       " tensor([[-0.2611,  0.6840, -0.0546]]),\n",
       " tensor([[-0.6226,  0.3783,  0.6448]]),\n",
       " tensor([[-0.5312,  0.1969,  0.4576]]),\n",
       " tensor([[0.2474, 0.2305, 0.3073]]),\n",
       " tensor([[-0.6856,  0.7101,  0.0945]]),\n",
       " tensor([[ 0.5731,  0.0588, -0.5877]]),\n",
       " tensor([[1.0612, 0.2288, 0.4872]]),\n",
       " tensor([[ 0.3485,  0.2412, -0.7047]]),\n",
       " tensor([[-0.0885, -0.0389,  0.1072]]),\n",
       " tensor([[ 0.1402,  0.8428, -0.7089]]),\n",
       " tensor([[-0.0605, -0.6192, -0.3141]]),\n",
       " tensor([[-1.6922,  0.1050, -0.4820]]),\n",
       " tensor([[-0.1117,  0.3709,  0.4084]]),\n",
       " tensor([[-0.4449,  0.7413, -0.4822]]),\n",
       " tensor([[-0.9283, -0.9030, -0.1740]]),\n",
       " tensor([[ 0.2850, -0.3978, -0.2521]]),\n",
       " tensor([[-0.3359, -0.3012,  0.5736]]),\n",
       " tensor([[ 0.6503, -0.5347, -1.9084]]),\n",
       " tensor([[-0.1167,  0.5306, -0.1063]]),\n",
       " tensor([[ 0.5162, -0.1266,  1.0306]]),\n",
       " tensor([[-0.3952, -0.1836, -0.2464]]),\n",
       " tensor([[-1.2562,  0.7699,  0.2759]]),\n",
       " tensor([[0.7183, 0.3720, 0.0837]]),\n",
       " tensor([[1.0763, 0.3902, 0.0663]]),\n",
       " tensor([[ 0.1223, -0.6085, -0.0497]]),\n",
       " tensor([[ 0.0406, -0.1434, -0.1308]]),\n",
       " tensor([[ 0.3448,  1.3647, -0.4809]]),\n",
       " tensor([[0.0528, 0.6233, 0.7807]]),\n",
       " tensor([[-0.5061,  0.7207, -0.0638]]),\n",
       " tensor([[-0.3365,  0.0090, -0.2651]]),\n",
       " tensor([[-0.1238,  0.2569, -0.0521]]),\n",
       " tensor([[-0.6891,  0.3067,  0.0215]]),\n",
       " tensor([[-0.2836,  0.2882, -0.4878]]),\n",
       " tensor([[ 0.5432, -0.2050, -0.4828]]),\n",
       " tensor([[ 0.1042,  1.1457, -0.9347]]),\n",
       " tensor([[ 0.6468, -0.8301, -0.4429]]),\n",
       " tensor([[ 0.2549, -0.3565,  0.5363]]),\n",
       " tensor([[0.3861, 1.0669, 0.5330]]),\n",
       " tensor([[ 0.1936, -0.0341,  0.5071]]),\n",
       " tensor([[-0.9406,  1.0841, -0.4832]]),\n",
       " tensor([[-0.5848,  0.3087,  0.0217]]),\n",
       " tensor([[ 0.3236, -0.3616, -0.2596]]),\n",
       " tensor([[ 0.4314, -0.0935,  0.0930]]),\n",
       " tensor([[-0.0113,  0.9358,  0.2673]]),\n",
       " tensor([[-0.4108, -0.0173, -0.0770]]),\n",
       " tensor([[-1.3547,  0.1187,  0.1824]]),\n",
       " tensor([[ 0.2853, -0.8722, -0.2116]]),\n",
       " tensor([[-1.3356,  0.0207, -0.0809]]),\n",
       " tensor([[0.7620, 0.8550, 0.1517]]),\n",
       " tensor([[0.7597, 0.7981, 0.1909]]),\n",
       " tensor([[0.1184, 1.1287, 0.0080]]),\n",
       " tensor([[ 0.3402, -0.8317, -0.9895]]),\n",
       " tensor([[1.3755, 0.0779, 0.7695]]),\n",
       " tensor([[-1.2185,  0.1274,  0.3658]]),\n",
       " tensor([[-0.5913,  0.8420,  0.0693]]),\n",
       " tensor([[ 0.6185,  1.0445, -1.0230]]),\n",
       " tensor([[0.8219, 0.6117, 0.1199]]),\n",
       " tensor([[0.8709, 0.6005, 0.3336]]),\n",
       " tensor([[ 0.9387,  0.7743, -0.6114]]),\n",
       " tensor([[-0.4613,  0.5483,  1.0860]]),\n",
       " tensor([[ 0.2463, -0.5339, -0.5654]]),\n",
       " tensor([[ 1.1226, -0.2965,  1.7782]]),\n",
       " tensor([[ 0.1918, -0.6276,  0.5984]]),\n",
       " tensor([[ 0.1410,  1.2059, -0.0233]]),\n",
       " tensor([[-0.0794, -0.7081,  0.5414]]),\n",
       " tensor([[ 0.6061,  0.1349, -0.4465]]),\n",
       " tensor([[-0.4317,  0.5408, -0.5655]]),\n",
       " tensor([[-0.5317,  0.1258,  0.2827]]),\n",
       " tensor([[-0.2096, -0.5369,  1.4963]]),\n",
       " tensor([[-0.2514,  0.5361, -0.2251]]),\n",
       " tensor([[ 0.1436, -0.5235,  0.0887]]),\n",
       " tensor([[ 0.7118, -0.0489, -1.0342]]),\n",
       " tensor([[-0.0440, -0.9256,  0.1704]]),\n",
       " tensor([[ 1.3094, -0.1011, -0.3820]]),\n",
       " tensor([[-0.7505,  1.2236, -0.3814]]),\n",
       " tensor([[ 0.6640,  0.0477, -0.3300]]),\n",
       " tensor([[ 0.1821,  0.3914, -0.5227]]),\n",
       " tensor([[0.8135, 0.6139, 0.8258]]),\n",
       " tensor([[-0.7973,  0.0750,  0.2338]]),\n",
       " tensor([[-0.0732,  0.3533, -0.3685]]),\n",
       " tensor([[0.7493, 0.4818, 0.7358]]),\n",
       " tensor([[-0.7701, -0.2799,  0.0011]]),\n",
       " tensor([[-0.6023, -0.0541,  0.3052]]),\n",
       " tensor([[ 0.0919,  0.5002, -0.1981]]),\n",
       " tensor([[0.8007, 0.2612, 0.8003]]),\n",
       " tensor([[-0.2489,  0.0054, -1.2671]]),\n",
       " tensor([[ 0.1871, -0.2738, -0.9295]]),\n",
       " tensor([[ 0.6546, -0.0423, -0.3908]]),\n",
       " tensor([[ 0.2403, -0.5611,  0.5128]]),\n",
       " tensor([[ 0.2472,  0.3419, -0.1474]]),\n",
       " tensor([[ 0.8921, -0.0692,  0.2258]]),\n",
       " tensor([[ 0.7881, -0.5150, -0.1494]]),\n",
       " tensor([[-0.2130,  0.1546,  1.8706]]),\n",
       " tensor([[ 0.0408,  0.8929, -0.1608]]),\n",
       " tensor([[-0.0228,  0.3892, -0.0311]]),\n",
       " tensor([[ 0.2745, -0.0824, -0.7720]]),\n",
       " tensor([[0.4121, 0.4187, 2.3663]]),\n",
       " tensor([[-0.3102, -0.3475,  0.2073]]),\n",
       " tensor([[ 0.3487, -0.0709,  0.3409]]),\n",
       " tensor([[ 0.5813, -0.9339, -0.1356]]),\n",
       " tensor([[-0.7649, -0.0748, -0.1600]]),\n",
       " tensor([[-0.5524, -0.0984, -0.8048]]),\n",
       " tensor([[ 0.1263, -0.0366,  0.5726]]),\n",
       " tensor([[0.9808, 1.4784, 0.4190]]),\n",
       " tensor([[-0.5045, -0.2699,  0.5514]]),\n",
       " tensor([[0.3916, 0.3090, 0.0091]]),\n",
       " tensor([[ 0.5112, -0.1736, -0.0152]]),\n",
       " tensor([[0.1070, 0.1203, 0.3703]]),\n",
       " tensor([[1.3007, 0.6969, 0.0998]]),\n",
       " tensor([[-0.9634, -0.4226,  1.3412]]),\n",
       " tensor([[ 0.7460, -0.1507, -0.4512]]),\n",
       " tensor([[ 1.8803, -0.3411, -0.3930]]),\n",
       " tensor([[-0.6583,  0.1788, -0.2035]]),\n",
       " tensor([[-1.6045,  0.4240,  1.1748]]),\n",
       " tensor([[-0.3393,  0.4443, -0.1628]]),\n",
       " tensor([[ 0.7636, -0.1068, -0.6566]]),\n",
       " tensor([[-0.5684,  1.0197, -0.6353]]),\n",
       " tensor([[ 0.3741, -0.4390,  1.2176]]),\n",
       " tensor([[ 0.0599, -0.1798,  0.1308]]),\n",
       " tensor([[-0.8026,  1.8673, -1.0622]]),\n",
       " tensor([[-0.6538,  0.6704,  0.6249]]),\n",
       " tensor([[-1.8665,  0.0246,  1.8213]]),\n",
       " tensor([[0.1739, 1.0413, 0.1878]]),\n",
       " tensor([[-0.6351,  0.2262,  0.1797]]),\n",
       " tensor([[ 0.3163,  0.1054, -0.0095]]),\n",
       " tensor([[ 0.5460,  0.5909, -0.2029]]),\n",
       " tensor([[ 0.6493,  0.2426, -0.4003]]),\n",
       " tensor([[0.9377, 0.4607, 0.9521]]),\n",
       " tensor([[-0.0235,  0.7861, -0.8998]]),\n",
       " tensor([[0.0615, 0.9199, 0.5180]]),\n",
       " tensor([[-0.2764,  0.0835,  0.7823]]),\n",
       " tensor([[-0.2365, -0.4042, -0.0948]]),\n",
       " tensor([[ 0.7839,  0.4918, -0.2356]]),\n",
       " tensor([[-0.2224,  0.5391,  0.5692]]),\n",
       " tensor([[-0.1407, -0.2486,  0.3696]]),\n",
       " tensor([[-0.1669,  0.4129,  0.6079]]),\n",
       " tensor([[0.8219, 0.6196, 0.1532]]),\n",
       " tensor([[-0.5739,  0.3466, -1.8239]]),\n",
       " tensor([[ 0.6978, -0.6372,  0.4197]]),\n",
       " tensor([[ 0.4634,  0.2751, -1.1296]]),\n",
       " tensor([[-0.3183, -0.1946,  0.6669]]),\n",
       " tensor([[-0.8717,  0.2843, -0.2455]]),\n",
       " tensor([[0.3847, 0.6563, 0.1388]]),\n",
       " tensor([[-0.7190,  0.3577, -1.4159]]),\n",
       " tensor([[-0.4011, -0.1925,  0.7197]]),\n",
       " tensor([[ 0.5540,  0.8163, -0.0992]]),\n",
       " tensor([[-0.6394,  0.3001,  0.0416]]),\n",
       " tensor([[ 0.6063, -0.1285,  0.8188]]),\n",
       " tensor([[-0.4206, -0.8141,  0.6100]]),\n",
       " tensor([[-0.1887,  0.0841, -0.3618]]),\n",
       " tensor([[0.3603, 0.1504, 0.2048]]),\n",
       " tensor([[-0.7032, -0.3316, -0.0178]]),\n",
       " tensor([[-0.6963,  0.2526, -0.4981]]),\n",
       " tensor([[ 0.5027,  0.3204, -0.2765]]),\n",
       " tensor([[ 0.2772,  0.0014, -0.0926]]),\n",
       " tensor([[-1.1500, -0.4830, -0.0862]]),\n",
       " tensor([[0.7415, 1.5550, 0.2853]]),\n",
       " tensor([[ 0.0756, -0.4190, -0.3572]]),\n",
       " tensor([[ 1.4519,  1.1796, -0.1036]]),\n",
       " tensor([[-1.4952, -0.0312,  1.0403]]),\n",
       " tensor([[ 0.5786, -0.9041, -0.8850]]),\n",
       " tensor([[-0.7012,  0.1081,  0.2744]]),\n",
       " tensor([[-0.3809, -0.1375,  1.0095]]),\n",
       " tensor([[-0.3727, -0.5625,  0.0878]]),\n",
       " tensor([[-0.6185, -0.5429, -1.5476]]),\n",
       " tensor([[ 0.2106, -0.2676, -0.4722]]),\n",
       " tensor([[ 0.4413,  0.1464, -0.7073]]),\n",
       " tensor([[ 0.2912,  0.0560, -0.7561]]),\n",
       " tensor([[-0.4956,  0.5076,  0.1689]]),\n",
       " tensor([[0.0272, 0.1366, 0.8657]]),\n",
       " tensor([[ 0.2386, -1.7165,  0.0025]]),\n",
       " tensor([[0.2641, 0.2974, 0.2218]]),\n",
       " tensor([[ 1.3890,  0.2562, -0.9051]]),\n",
       " tensor([[ 0.0556,  0.5763, -0.6804]]),\n",
       " tensor([[ 0.3998,  0.2829, -0.4843]]),\n",
       " tensor([[-0.0984, -0.9670,  0.1366]]),\n",
       " tensor([[-0.0489,  0.3536, -0.2542]]),\n",
       " tensor([[-0.8549, -0.3066,  0.8522]]),\n",
       " tensor([[-0.0812,  0.0609,  0.3499]]),\n",
       " tensor([[-1.0377,  0.3791,  0.2910]]),\n",
       " tensor([[ 0.2005,  0.7285, -1.1566]]),\n",
       " tensor([[-0.3201,  0.1079, -0.1142]]),\n",
       " tensor([[-0.2389,  0.0674,  0.2174]]),\n",
       " tensor([[-0.0192,  0.9889,  0.5427]]),\n",
       " tensor([[-0.1714,  0.0779,  0.3082]]),\n",
       " tensor([[2.1514, 0.5728, 0.5016]]),\n",
       " tensor([[-0.3704,  0.0432, -0.5043]]),\n",
       " tensor([[ 0.0490, -0.6393, -0.2828]]),\n",
       " tensor([[-0.6171,  1.5071, -0.1204]]),\n",
       " tensor([[-0.1814,  0.1747,  0.1769]]),\n",
       " tensor([[-0.6047,  0.1351, -0.4745]]),\n",
       " tensor([[-0.0626,  0.6770,  0.2564]]),\n",
       " tensor([[ 0.1933,  0.8472, -1.1025]]),\n",
       " tensor([[0.1654, 1.2864, 0.5689]]),\n",
       " tensor([[0.0037, 0.6191, 0.1808]]),\n",
       " tensor([[1.0349, 0.2738, 0.1090]]),\n",
       " tensor([[-0.6120,  0.8061,  1.5339]]),\n",
       " tensor([[-0.4162,  1.1430,  0.2536]]),\n",
       " tensor([[ 0.1572,  0.6631, -0.0502]]),\n",
       " tensor([[0.2010, 0.5359, 0.2532]]),\n",
       " tensor([[-0.2675, -1.1639,  1.0597]]),\n",
       " tensor([[-0.2440, -0.6236, -0.6968]]),\n",
       " tensor([[ 0.2770, -0.0777, -0.5394]]),\n",
       " tensor([[-0.1728,  0.6019, -0.6380]]),\n",
       " tensor([[ 0.1359,  0.3072, -0.7207]]),\n",
       " tensor([[0.2711, 0.6357, 0.7154]]),\n",
       " tensor([[-0.5851, -0.5776,  0.0072]]),\n",
       " tensor([[-0.1928, -0.2015, -1.0108]]),\n",
       " tensor([[1.6443, 0.7047, 0.2712]]),\n",
       " tensor([[-0.1489, -0.4302,  0.1835]]),\n",
       " tensor([[0.9537, 0.2419, 0.8387]]),\n",
       " tensor([[-0.2468, -0.4050, -0.2098]]),\n",
       " tensor([[ 1.5581, -0.1941,  0.3094]]),\n",
       " tensor([[-0.4468,  0.8899,  1.2630]]),\n",
       " tensor([[ 0.9444, -0.3122, -0.1691]]),\n",
       " tensor([[ 0.8816,  0.1939, -0.1440]]),\n",
       " tensor([[ 0.3572, -0.2897, -0.5325]]),\n",
       " tensor([[-0.5629,  0.2915, -0.3979]]),\n",
       " tensor([[ 0.6950,  0.0469, -0.0862]]),\n",
       " tensor([[-0.2674,  0.8810,  0.5658]]),\n",
       " tensor([[ 0.2660, -0.0878,  0.4182]]),\n",
       " tensor([[0.8550, 1.2401, 0.2538]]),\n",
       " tensor([[-0.0384,  0.7523,  0.7381]]),\n",
       " tensor([[ 0.1275,  0.2386, -0.2546]]),\n",
       " tensor([[-0.9172, -0.7301, -0.5468]]),\n",
       " tensor([[-0.2313,  1.0255, -0.1566]]),\n",
       " tensor([[-0.1947, -0.4766, -0.5241]]),\n",
       " tensor([[ 0.0277,  0.0987, -0.8549]]),\n",
       " tensor([[ 0.6890, -1.3873,  0.4487]]),\n",
       " tensor([[1.4093, 0.3655, 1.0803]]),\n",
       " tensor([[-0.2199, -0.2152,  1.1807]]),\n",
       " tensor([[-0.8760, -1.3786,  0.4093]]),\n",
       " tensor([[ 0.1004,  0.4412, -1.5965]]),\n",
       " tensor([[-1.5245, -1.0050,  0.8601]]),\n",
       " tensor([[ 0.7524,  0.6478, -0.0030]]),\n",
       " tensor([[ 0.5622, -0.2664,  1.3413]]),\n",
       " tensor([[-0.2189, -0.6608,  0.2856]]),\n",
       " tensor([[ 0.1604, -0.3242,  0.1729]]),\n",
       " tensor([[ 0.6565, -0.1330, -0.9431]]),\n",
       " tensor([[-0.6130,  1.1054,  0.6009]]),\n",
       " tensor([[-0.6222,  0.5005, -1.0747]]),\n",
       " tensor([[ 0.2312,  0.2353, -0.3128]]),\n",
       " tensor([[-0.3748,  0.4200,  0.1250]]),\n",
       " tensor([[-0.4352,  0.6353,  1.3681]]),\n",
       " tensor([[ 0.3559, -0.7316, -0.7427]]),\n",
       " tensor([[ 0.1119, -0.2705, -0.2373]]),\n",
       " tensor([[-0.0497, -0.4016,  0.1876]]),\n",
       " tensor([[-0.4161,  0.0088, -0.0892]]),\n",
       " tensor([[1.0838, 0.3078, 0.4573]]),\n",
       " tensor([[-0.8375,  0.3464, -0.2597]]),\n",
       " tensor([[-0.3212, -0.1245,  0.4208]]),\n",
       " tensor([[1.2187, 0.5436, 0.3935]]),\n",
       " tensor([[-0.9237,  0.2912,  0.4168]]),\n",
       " tensor([[-0.4970, -0.3151, -1.3973]]),\n",
       " tensor([[ 0.7951, -0.3835, -1.3338]]),\n",
       " tensor([[ 0.6213, -0.0263, -0.4625]]),\n",
       " tensor([[ 0.0762, -1.0485,  0.7746]]),\n",
       " tensor([[ 0.6237, -0.1294, -0.3683]]),\n",
       " tensor([[-0.4453,  1.0839, -0.0997]]),\n",
       " tensor([[0.1564, 0.6933, 0.6641]]),\n",
       " tensor([[ 0.2978,  0.2054, -0.7296]]),\n",
       " tensor([[-0.1568, -1.3028,  0.0434]]),\n",
       " tensor([[ 0.1862,  0.6040, -0.4678]]),\n",
       " tensor([[ 0.6723, -0.4187,  0.6260]]),\n",
       " tensor([[-0.7958,  0.0958, -0.6414]]),\n",
       " tensor([[ 0.0081,  0.3970, -1.2951]]),\n",
       " tensor([[ 0.0947, -0.2855, -0.1756]]),\n",
       " tensor([[ 1.1292, -0.9658,  0.1119]]),\n",
       " tensor([[ 0.0934,  1.3493, -0.0852]]),\n",
       " tensor([[ 0.6347, -0.1642,  0.9106]]),\n",
       " tensor([[-0.1603, -0.1563,  0.2612]]),\n",
       " tensor([[-0.3432,  0.2431, -0.2279]]),\n",
       " tensor([[-0.7179, -0.7301, -0.9478]]),\n",
       " tensor([[-0.4186,  0.3204, -0.2298]]),\n",
       " tensor([[-0.0397,  0.3909, -0.2751]]),\n",
       " tensor([[-0.5433, -0.3407,  0.8335]]),\n",
       " tensor([[-0.4793, -0.8978,  0.1194]]),\n",
       " tensor([[-0.0300,  0.2432,  0.5231]]),\n",
       " tensor([[ 0.1528, -0.0739,  0.6033]]),\n",
       " tensor([[-0.5831, -0.4750, -0.3648]]),\n",
       " tensor([[-0.7472,  1.0438, -0.2118]]),\n",
       " tensor([[ 1.1795, -0.4893, -0.4473]]),\n",
       " tensor([[-0.3258,  0.0963, -0.7617]]),\n",
       " tensor([[ 0.7649,  0.4126, -0.1805]]),\n",
       " tensor([[-0.4730,  0.4661,  0.4546]]),\n",
       " tensor([[ 0.4691, -0.3391, -0.0487]]),\n",
       " tensor([[0.6778, 0.9762, 0.1128]]),\n",
       " tensor([[-0.4303,  1.0740,  0.4074]]),\n",
       " tensor([[-0.1574, -0.1059,  0.2971]]),\n",
       " tensor([[-0.4862,  0.2504,  0.0687]]),\n",
       " tensor([[-0.8004, -0.1310,  0.1781]]),\n",
       " tensor([[ 0.0581,  0.1996, -0.5175]]),\n",
       " tensor([[ 0.0557, -0.2242, -0.1931]]),\n",
       " tensor([[-0.2447, -0.3595,  0.7478]]),\n",
       " tensor([[-0.4661,  0.0716,  1.0378]]),\n",
       " tensor([[ 0.9743,  0.5856, -0.4733]]),\n",
       " tensor([[ 0.3420, -0.4178, -0.5041]]),\n",
       " tensor([[ 0.8235, -1.1700,  0.8462]]),\n",
       " tensor([[-1.6313, -0.0798, -0.2855]]),\n",
       " tensor([[ 0.0245,  0.0067, -0.5346]]),\n",
       " tensor([[0.2488, 0.0913, 0.2499]]),\n",
       " tensor([[ 0.0853,  0.9451, -0.0096]]),\n",
       " tensor([[-0.3607,  0.2244, -0.5565]]),\n",
       " tensor([[-0.1174,  0.7124,  0.5473]]),\n",
       " tensor([[-1.2259,  0.8850, -0.0370]]),\n",
       " tensor([[-0.4076, -0.6092, -0.1637]]),\n",
       " tensor([[ 0.3479, -0.3647,  1.1558]]),\n",
       " tensor([[ 0.1628, -0.1276, -0.9718]]),\n",
       " tensor([[-1.6412,  0.7261, -0.1378]]),\n",
       " tensor([[ 0.1278, -0.6079, -0.9218]]),\n",
       " tensor([[ 1.0154,  0.2959, -0.5415]]),\n",
       " tensor([[-0.9351,  0.4056, -0.2993]]),\n",
       " tensor([[ 0.4696, -0.5562,  0.5981]]),\n",
       " tensor([[-0.9778, -0.4778, -0.9963]]),\n",
       " tensor([[ 0.1250,  0.7042, -0.1575]]),\n",
       " tensor([[ 1.0134, -0.1355, -0.1234]]),\n",
       " tensor([[ 0.6176,  0.0064, -0.3041]]),\n",
       " tensor([[ 1.0627, -0.3112,  0.3105]]),\n",
       " tensor([[-0.2411,  0.2532, -0.3089]]),\n",
       " tensor([[ 0.6421,  0.0851, -0.5480]]),\n",
       " tensor([[0.7315, 0.5377, 0.1768]]),\n",
       " tensor([[-0.8052, -0.1986,  0.3902]]),\n",
       " tensor([[0.5003, 0.1311, 0.7451]]),\n",
       " tensor([[-0.2858,  0.1639,  0.2973]]),\n",
       " tensor([[-1.1435,  0.2487, -0.2682]]),\n",
       " tensor([[ 0.3278, -0.3021, -0.5126]]),\n",
       " tensor([[-0.3010,  0.0149,  0.3786]]),\n",
       " tensor([[-0.3431,  0.7536,  0.6940]]),\n",
       " tensor([[ 0.3139, -0.2915, -0.7564]]),\n",
       " tensor([[0.9025, 0.5507, 0.5201]]),\n",
       " tensor([[-1.0666,  0.7163,  1.1941]]),\n",
       " tensor([[-0.3391,  0.8655,  0.7597]]),\n",
       " tensor([[ 0.5969, -0.4130, -0.0356]]),\n",
       " tensor([[-0.7298,  0.0230,  0.3977]]),\n",
       " tensor([[1.1462, 0.7580, 0.1950]]),\n",
       " tensor([[-0.8277, -0.6464,  0.3926]]),\n",
       " tensor([[ 0.2439, -0.3225, -0.4721]]),\n",
       " tensor([[-0.9208, -0.8595,  0.1346]]),\n",
       " tensor([[-0.4527,  0.7888,  0.9005]]),\n",
       " tensor([[ 0.0943,  0.7773, -0.5148]]),\n",
       " tensor([[-0.7930, -0.0726,  0.9107]]),\n",
       " tensor([[-0.1141,  0.1464,  0.3941]]),\n",
       " tensor([[0.5437, 1.0530, 0.6159]]),\n",
       " tensor([[0.5552, 0.1527, 1.0813]]),\n",
       " tensor([[ 0.2096,  0.4540, -0.7352]]),\n",
       " tensor([[ 0.7528, -0.6351, -1.2227]]),\n",
       " tensor([[-0.2666,  0.0587, -0.0874]]),\n",
       " tensor([[0.2286, 0.8494, 1.5010]]),\n",
       " tensor([[ 0.0378, -0.1278,  0.6455]]),\n",
       " tensor([[ 0.2886, -1.2125,  0.2454]]),\n",
       " tensor([[-0.2179, -0.4402,  0.3498]]),\n",
       " tensor([[ 1.0653, -1.2519, -1.1616]]),\n",
       " tensor([[-0.6732,  0.5270,  0.1320]]),\n",
       " tensor([[ 0.1182,  0.1399, -0.7507]]),\n",
       " tensor([[0.4591, 1.2345, 0.0590]]),\n",
       " tensor([[-1.2705,  0.5738, -0.0855]]),\n",
       " tensor([[-0.1127,  1.0822, -0.5517]]),\n",
       " tensor([[0.5988, 0.6915, 0.4588]]),\n",
       " tensor([[-0.4529,  0.0767,  0.3172]]),\n",
       " tensor([[ 1.5966,  0.1622, -0.8894]]),\n",
       " tensor([[ 0.2378,  0.8265, -0.6107]]),\n",
       " tensor([[-0.2052,  0.2602,  0.8547]]),\n",
       " tensor([[ 0.4629, -0.3995,  0.6316]]),\n",
       " tensor([[-1.0950, -0.4130,  0.3436]]),\n",
       " tensor([[ 0.0701, -1.0708,  1.3330]]),\n",
       " tensor([[0.5170, 0.3063, 0.2355]]),\n",
       " tensor([[0.2197, 0.2437, 0.0240]]),\n",
       " tensor([[-0.6627, -0.0316, -0.0150]]),\n",
       " tensor([[-0.6424,  0.7854, -1.2920]]),\n",
       " tensor([[ 0.1120, -0.5170, -0.4050]]),\n",
       " tensor([[ 0.7056, -0.2410, -0.1465]]),\n",
       " tensor([[0.4299, 0.6211, 0.3251]]),\n",
       " tensor([[0.0542, 0.8409, 0.9681]]),\n",
       " tensor([[-1.0355, -0.1518,  0.1745]]),\n",
       " tensor([[-1.0244,  0.1399,  0.0325]]),\n",
       " tensor([[1.2891, 0.0703, 0.0971]]),\n",
       " tensor([[-0.0095,  0.4501,  0.2212]]),\n",
       " tensor([[1.4214, 0.7666, 0.3591]]),\n",
       " tensor([[ 0.2178, -1.0107,  0.2131]]),\n",
       " tensor([[-0.1871,  0.3135, -0.5949]]),\n",
       " tensor([[ 0.2887, -0.2470,  0.5613]]),\n",
       " tensor([[-1.2837, -0.2855,  0.3709]]),\n",
       " tensor([[-0.1962,  0.0570,  0.2098]]),\n",
       " tensor([[-0.2779,  1.5549,  0.3007]]),\n",
       " tensor([[ 0.3447,  0.0878, -0.4288]]),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_agent.buffer.actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc6b4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_states = torch.squeeze(torch.stack(ppo_agent.buffer.states, dim=0)).detach().to(device)\n",
    "old_actions = torch.squeeze(torch.stack(ppo_agent.buffer.actions, dim=0)).detach().to(device)\n",
    "old_logprobs = torch.squeeze(torch.stack(ppo_agent.buffer.logprobs, dim=0)).detach().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb0eca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3665, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "200a75c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3665, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "358ba2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3665])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa8a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
